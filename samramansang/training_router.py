"""
Training Router Module
í•™ìŠµ ê´€ë ¨ API ì—”ë“œí¬ì¸íŠ¸ë“¤ì„ ê´€ë¦¬í•˜ëŠ” ëª¨ë“ˆ
"""

import subprocess
import threading
import json
import os
import glob
import time
import re
import logging
from aiohttp import web

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('training')


# ì „ì—­ í•™ìŠµ ê´€ë¦¬ì
training_process = None
training_status = {
    'state': 'idle',
    'is_running': False,
    'is_complete': False,
    'current_step': '',
    'progress': 0,
    'current_epoch': 0,
    'total_epochs': 0,
    'current_loss': 0,
    'best_loss': None,
    'start_time': None,
    'log_entries': []
}
training_lock = threading.Lock()


def run_clustering_only_pipeline(config):
    """í´ëŸ¬ìŠ¤í„°ë§ë§Œ ì‹¤í–‰í•˜ëŠ” íŒŒì´í”„ë¼ì¸"""
    global training_status
    
    logger.info(f"ğŸš€ í´ëŸ¬ìŠ¤í„°ë§ ì „ìš© íŒŒì´í”„ë¼ì¸ ì‹œì‘: {config}")
    
    # í´ëŸ¬ìŠ¤í„°ë§ ì „ìš© ëª¨ë“œì—ì„œë„ is_running ìƒíƒœ ì„¤ì •
    with training_lock:
        training_status['is_running'] = True
        training_status['state'] = 'running'
        training_status['is_complete'] = False
        logger.info("âœ… í´ëŸ¬ìŠ¤í„°ë§ ëª¨ë“œì—ì„œ is_running = True ì„¤ì •")
    
    try:
        # 1. í´ëŸ¬ìŠ¤í„°ë§ ë° ì„¸ê·¸ë¨¼íŠ¸í™”
        with training_lock:
            training_status['current_step'] = 'í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘'
            training_status['progress'] = 60
            logger.info("ğŸ“Š í´ëŸ¬ìŠ¤í„°ë§ ë‹¨ê³„ ì‹œì‘")
        
        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        embeddings_path = config.get('embeddings_path', 'runs/embeddings.npy')
        if not os.path.isabs(embeddings_path):
            embeddings_path = os.path.abspath(embeddings_path)
        
        logger.info(f"ğŸ“ ì„ë² ë”© íŒŒì¼ ê²½ë¡œ: {embeddings_path}")
        logger.info(f"ğŸ“ ì„ë² ë”© íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(embeddings_path)}")
        
        cluster_cmd = [
            'python', 'cluster_and_segment.py',
            '--embeddings', embeddings_path,
            '--out', 'runs/segments.json',
            '--algo', config.get('algorithm', 'hdbscan'),
            '--k', str(config.get('clusters', 8)),
            '--min_len', str(config.get('min_length', 5)),
            '--merge_gap', str(config.get('merge_gap', 2)),
            '--split_criterion', config.get('split_criterion', 'neutral'),
            '--max_len_windows', str(config.get('max_len_windows', 10)),
            '--window', str(config['window']),
            '--stride', str(config['stride'])
        ]
        # Optional edge trimming towards neutral
        if config.get('trim_edges'):
            cluster_cmd += ['--trim_edges']
        cluster_cmd += ['--edge_radius', str(config.get('edge_radius', 3))]
        
        # HDBSCAN ì „ìš© íŒŒë¼ë¯¸í„°
        if config.get('algorithm') == 'hdbscan':
            cluster_cmd.extend([
                '--hdb_min_cluster', str(config.get('hdb_min_cluster', 5)),
                '--hdb_min_samples', str(config.get('hdb_min_samples', 3))
            ])
        
        # Ensure unbuffered python for real-time logs
        if cluster_cmd and cluster_cmd[0] == 'python':
            cluster_cmd.insert(1, '-u')
        logger.info(f"ğŸ”§ í´ëŸ¬ìŠ¤í„°ë§ ëª…ë ¹ì–´: {' '.join(cluster_cmd)}")
        print(f"[CLUSTERING] {' '.join(cluster_cmd)}")
        # Stream logs line-by-line
        process = subprocess.Popen(
            cluster_cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=1
        )
        for line in iter(process.stdout.readline, ''):
            if not training_status['is_running']:
                try:
                    process.terminate()
                except Exception:
                    pass
                break
            s = line.rstrip('\n')
            if s:
                print(f"[CLUSTERING] {s}")
                with training_lock:
                    training_status['log_entries'].append({
                        'message': s,
                        'level': 'info',
                        'timestamp': time.time(),
                        'epoch': 0,
                        'step': training_status.get('current_step', '')
                    })
                    if len(training_status['log_entries']) > 200:
                        training_status['log_entries'] = training_status['log_entries'][-200:]
        rc = process.wait()
        if rc != 0:
            raise subprocess.CalledProcessError(rc, cluster_cmd)
        
        with training_lock:
            training_status['current_step'] = 'í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ'
            training_status['progress'] = 75
            logger.info("âœ… í´ëŸ¬ìŠ¤í„°ë§ ë‹¨ê³„ ì™„ë£Œ")
        
        # 2. ëŒ€í‘œ ìƒ˜í”Œ ì„ íƒ
        with training_lock:
            training_status['current_step'] = 'ëŒ€í‘œ ìƒ˜í”Œ ì„ íƒ ì¤‘'
            training_status['progress'] = 85
            logger.info("ğŸ¯ ëŒ€í‘œ ìƒ˜í”Œ ì„ íƒ ë‹¨ê³„ ì‹œì‘")
        
        reps_cmd = [
            'python', 'select_representatives.py',
            '--embeddings', embeddings_path,
            '--segments', 'runs/segments.json',
            '--method', str(config.get('rep_method', 'per_label_k')),
            '--per_label_k', str(config.get('rep_k', 5)),
            '--threshold', str(config.get('rep_thr', 0.25)),
            '--out', 'runs/segments_representative.json'
        ]
        # Ensure unbuffered python for real-time logs
        if reps_cmd and reps_cmd[0] == 'python':
            reps_cmd.insert(1, '-u')
        logger.info(f"ğŸ”§ ëŒ€í‘œ ìƒ˜í”Œ ì„ íƒ ëª…ë ¹ì–´: {' '.join(reps_cmd)}")
        print(f"[REPRESENTATIVES] {' '.join(reps_cmd)}")
        reps_proc = subprocess.Popen(
            reps_cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=1
        )
        for line in iter(reps_proc.stdout.readline, ''):
            if not training_status['is_running']:
                try:
                    reps_proc.terminate()
                except Exception:
                    pass
                break
            s = line.rstrip('\n')
            if s:
                print(f"[REPRESENTATIVES] {s}")
                with training_lock:
                    training_status['log_entries'].append({
                        'message': s,
                        'level': 'info',
                        'timestamp': time.time(),
                        'epoch': 0,
                        'step': training_status.get('current_step', '')
                    })
                    if len(training_status['log_entries']) > 200:
                        training_status['log_entries'] = training_status['log_entries'][-200:]
        rc = reps_proc.wait()
        if rc != 0:
            raise subprocess.CalledProcessError(rc, reps_cmd)
        
        with training_lock:
            training_status['current_step'] = 'í´ëŸ¬ìŠ¤í„°ë§ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ'
            training_status['progress'] = 100
            training_status['is_running'] = False
            training_status['state'] = 'completed'
            training_status['is_complete'] = True
            logger.info("ğŸ‰ í´ëŸ¬ìŠ¤í„°ë§ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            
            # ì™„ë£Œ ë©”ì‹œì§€ê°€ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
            completion_message = 'ğŸ‰ í´ëŸ¬ìŠ¤í„°ë§ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!'
            existing_messages = [entry['message'] for entry in training_status['log_entries']]
            
            if completion_message not in existing_messages:
                training_status['log_entries'].append({
                    'message': completion_message,
                    'level': 'success',
                    'timestamp': time.time(),
                    'epoch': 0,
                    'step': 'ì™„ë£Œ'
                })
    
    except subprocess.CalledProcessError as e:
        logger.error(f"âŒ í´ëŸ¬ìŠ¤í„°ë§ subprocess ì‹¤íŒ¨: {e}")
        logger.error(f"âŒ stderr: {e.stderr}")
        logger.error(f"âŒ stdout: {e.stdout}")
        with training_lock:
            training_status['current_step'] = 'í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨'
            training_status['is_running'] = False
            training_status['state'] = 'failed'
            training_status['is_complete'] = False
            training_status['log_entries'].append({
                'message': f'âŒ í´ëŸ¬ìŠ¤í„°ë§ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e.stderr}',
                'level': 'error',
                'timestamp': time.time(),
                'epoch': 0,
                'step': 'ì‹¤íŒ¨'
            })
    except Exception as e:
        logger.error(f"âŒ í´ëŸ¬ìŠ¤í„°ë§ ì¼ë°˜ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        with training_lock:
            training_status['current_step'] = 'í´ëŸ¬ìŠ¤í„°ë§ ì˜¤ë¥˜'
            training_status['is_running'] = False
            training_status['state'] = 'failed'
            training_status['is_complete'] = False
            training_status['log_entries'].append({
                'message': f'âŒ í´ëŸ¬ìŠ¤í„°ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
                'level': 'error',
                'timestamp': time.time(),
                'epoch': 0,
                'step': 'ì˜¤ë¥˜'
            })


def run_training_pipeline(config):
    """í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    global training_status
    
    logger.info(f"ğŸš€ ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘: {config}")
    
    try:
        training_mode = config.get('training_mode', 'full')
        logger.info(f"ğŸ“‹ í•™ìŠµ ëª¨ë“œ: {training_mode}")
        
        with training_lock:
            training_status['is_running'] = True  # íŒŒì´í”„ë¼ì¸ ì‹œì‘ ì‹œ is_running ì„¤ì •
            training_status['state'] = 'running'
            training_status['is_complete'] = False
            if training_mode == 'full':
                training_status['current_step'] = 'ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œì‘'
                training_status['progress'] = 5
            else:
                training_status['current_step'] = 'í´ëŸ¬ìŠ¤í„°ë§ë§Œ ì‹œì‘'
                training_status['progress'] = 60  # í´ëŸ¬ìŠ¤í„°ë§ ë‹¨ê³„ë¶€í„° ì‹œì‘
        
        # training í´ë”ë¡œ ì´ë™
        training_dir = os.path.join(os.getcwd(), 'training')
        logger.info(f"ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½: {training_dir}")
        os.chdir(training_dir)
        logger.info(f"ğŸ“ í˜„ì¬ ë””ë ‰í† ë¦¬: {os.getcwd()}")
        
        if training_mode == 'full':
            # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            logger.info("ğŸ”„ ì „ì²´ íŒŒì´í”„ë¼ì¸ ëª¨ë“œ ì‹¤í–‰")
            cmd = [
                'python', 'run_pipeline.py',
                '--data_glob', config['data_glob'],
                '--window', str(config['window']),
                '--stride', str(config['stride']),
                '--epochs', str(config['epochs']),
                '--batch_size', str(config['batch_size']),
                '--lr', str(config['lr']),
                '--weight_decay', str(config.get('weight_decay', 1e-4)),
                '--temperature', str(config.get('temperature', 0.1)),
                '--workers', str(config.get('workers', 4)),
                '--device', 'cuda' if os.system('nvidia-smi > /dev/null 2>&1') == 0 else 'cpu',
                '--algo', config.get('algorithm', 'hdbscan'),
                '--k', str(config.get('clusters', 8)),
                '--min_len', str(config.get('min_length', 5)),
                '--merge_gap', str(config.get('merge_gap', 2)),
                '--split_criterion', config.get('split_criterion', 'neutral'),
                '--max_len_windows', str(config.get('max_len_windows', 10)),
                # edge trimming
                *(['--trim_edges'] if config.get('trim_edges') else []),
                '--edge_radius', str(config.get('edge_radius', 3)),
                '--rep_method', config.get('rep_method', 'per_label_k'),
                '--rep_k', str(config.get('rep_k', 5)),
                '--rep_thr', str(config.get('rep_thr', 0.25))
            ]
            
            # HDBSCAN ì „ìš© íŒŒë¼ë¯¸í„°
            if config.get('algorithm') == 'hdbscan':
                cmd.extend([
                    '--hdb_min_cluster', str(config.get('hdb_min_cluster', 5)),
                    '--hdb_min_samples', str(config.get('hdb_min_samples', 3))
                ])
        
        else:  # training_mode == 'clustering'
            # í´ëŸ¬ìŠ¤í„°ë§ë§Œ ì‹¤í–‰ (ì—¬ëŸ¬ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ ì‹¤í–‰)
            logger.info("ğŸ¯ í´ëŸ¬ìŠ¤í„°ë§ ì „ìš© ëª¨ë“œ ì‹¤í–‰")
            run_clustering_only_pipeline(config)
            return
        
        with training_lock:
            if training_mode == 'full':
                training_status['current_step'] = 'SimCLR í•™ìŠµ ì‹œì‘'
                training_status['progress'] = 10
            else:
                training_status['current_step'] = 'í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘'
                training_status['progress'] = 60
        
        # í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
        logger.info(f"ğŸ”§ ì „ì²´ íŒŒì´í”„ë¼ì¸ ëª…ë ¹ì–´: {' '.join(cmd)}")
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=1
        )
        logger.info(f"ğŸš€ í”„ë¡œì„¸ìŠ¤ ì‹œì‘: PID={process.pid}")
        
        # ì‹¤ì‹œê°„ ì¶œë ¥ ì²˜ë¦¬
        logger.info("ğŸ“Š ì‹¤ì‹œê°„ ì¶œë ¥ ì²˜ë¦¬ ì‹œì‘")
        for line in iter(process.stdout.readline, ''):
            if not training_status['is_running']:
                logger.warning("âš ï¸ í•™ìŠµ ì¤‘ì§€ ìš”ì²­ë¨")
                process.terminate()
                break
                
            line = line.strip()
            if line:
                print(f"[TRAINING] {line}")
                
                # ì§„í–‰ ìƒí™© íŒŒì‹± - ìƒˆë¡œìš´ í˜•ì‹: [Ep 001] loss=7.3521 lr=0.001000 time=3.0s
                if '[Ep' in line and ']' in line:
                    try:
                        # "[Ep 001]" í˜•íƒœì—ì„œ í˜„ì¬ ì—í¬í¬ ì¶”ì¶œ
                        import re
                        epoch_match = re.search(r'\[Ep\s+(\d+)\]', line)
                        if epoch_match:
                            current_epoch = int(epoch_match.group(1))
                            with training_lock:
                                training_status['current_epoch'] = current_epoch
                                # ì´ ì—í¬í¬ ìˆ˜ëŠ” ì„¤ì •ì—ì„œ ê°€ì ¸ì˜´ (ê¸°ë³¸ê°’ 100)
                                total_epochs = training_status.get('total_epochs', 100)
                                training_status['progress'] = 10 + (current_epoch / total_epochs) * 60
                    except:
                        pass
                
                # ì†ì‹¤ ê°’ íŒŒì‹± - ìƒˆë¡œìš´ í˜•ì‹: loss=7.3521
                if 'loss=' in line.lower():
                    try:
                        # "loss=7.3521" í˜•íƒœì—ì„œ ì†ì‹¤ ê°’ ì¶”ì¶œ
                        loss_match = re.search(r'loss=([\d.]+)', line.lower())
                        if loss_match:
                            loss = float(loss_match.group(1))
                            with training_lock:
                                training_status['current_loss'] = loss
                                if training_status['best_loss'] is None or loss < training_status['best_loss']:
                                    training_status['best_loss'] = loss
                    except:
                        pass
                
                # ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                if training_mode == 'full':
                    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì§„í–‰ ìƒí™©
                    if 'Done.' in line:
                        with training_lock:
                            training_status['current_step'] = 'SimCLR í•™ìŠµ ì™„ë£Œ'
                            training_status['progress'] = 30
                    elif 'extract_embeddings.py' in line:
                        with training_lock:
                            training_status['current_step'] = 'ì„ë² ë”© ì¶”ì¶œ ì¤‘'
                            training_status['progress'] = 60
                    elif 'viz_embeddings.py' in line:
                        with training_lock:
                            training_status['current_step'] = '2D ì„ë² ë”© ì‹œê°í™” ì¤‘'
                            training_status['progress'] = 70
                    elif 'cluster_and_segment.py' in line:
                        with training_lock:
                            training_status['current_step'] = 'í´ëŸ¬ìŠ¤í„°ë§ ì¤‘'
                            training_status['progress'] = 75
                    elif 'select_representatives.py' in line:
                        with training_lock:
                            training_status['current_step'] = 'ëŒ€í‘œ ìƒ˜í”Œ ì„ íƒ ì¤‘'
                            training_status['progress'] = 85
                    elif 'export_representative_parquet.py' in line:
                        with training_lock:
                            training_status['current_step'] = 'Parquet íŒŒì¼ ìƒì„± ì¤‘'
                            training_status['progress'] = 90
                    elif 'Pipeline done.' in line:
                        with training_lock:
                            training_status['current_step'] = 'ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ'
                            training_status['progress'] = 100
                else:
                    # í´ëŸ¬ìŠ¤í„°ë§ë§Œ ëª¨ë“œ ì§„í–‰ ìƒí™©
                    if 'labels:' in line:
                        with training_lock:
                            training_status['current_step'] = 'í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ'
                            training_status['progress'] = 80
                    elif 'Saved segments:' in line:
                        with training_lock:
                            training_status['current_step'] = 'ì„¸ê·¸ë¨¼íŠ¸í™” ì™„ë£Œ'
                            training_status['progress'] = 100
                
                # ë¡œê·¸ ë ˆë²¨ ê²°ì •
                log_level = 'info'
                if any(keyword in line.lower() for keyword in ['error', 'failed', 'exception', 'traceback']):
                    log_level = 'error'
                elif any(keyword in line.lower() for keyword in ['warning', 'warn', 'deprecated', 'futurewarning']):
                    log_level = 'warning'
                elif any(keyword in line.lower() for keyword in ['success', 'completed', 'finished', 'done', 'saved', 'wrote']):
                    log_level = 'success'
                elif any(keyword in line.lower() for keyword in ['[ep', 'loss=', 'lr=', 'time=']):
                    log_level = 'training'
                
                # ë¡œê·¸ ì—”íŠ¸ë¦¬ ì¶”ê°€
                with training_lock:
                    training_status['log_entries'].append({
                        'message': line,
                        'level': log_level,
                        'timestamp': time.time(),
                        'epoch': training_status.get('current_epoch', 0),
                        'step': training_status.get('current_step', '')
                    })
                    # ìµœëŒ€ 200ê°œ ë¡œê·¸ ì—”íŠ¸ë¦¬ë§Œ ìœ ì§€
                    if len(training_status['log_entries']) > 200:
                        training_status['log_entries'] = training_status['log_entries'][-200:]
        
        # í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ëŒ€ê¸°
        logger.info("â³ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ëŒ€ê¸° ì¤‘...")
        return_code = process.wait()
        logger.info(f"ğŸ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ: ì¢…ë£Œ ì½”ë“œ={return_code}")
        
        with training_lock:
            if return_code == 0:
                logger.info("âœ… í”„ë¡œì„¸ìŠ¤ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ")
                if training_mode == 'full':
                    training_status['current_step'] = 'ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ'
                    completion_message = 'ğŸ‰ ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!'
                else:
                    training_status['current_step'] = 'í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ'
                    completion_message = 'ğŸ‰ í´ëŸ¬ìŠ¤í„°ë§ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!'
                
                training_status['progress'] = 100
                training_status['is_running'] = False
                training_status['state'] = 'completed'
                training_status['is_complete'] = True
                
                # ì™„ë£Œ ë©”ì‹œì§€ê°€ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
                existing_messages = [entry['message'] for entry in training_status['log_entries']]
                if completion_message not in existing_messages:
                    training_status['log_entries'].append({
                        'message': completion_message,
                        'level': 'success',
                        'timestamp': time.time(),
                        'epoch': training_status.get('current_epoch', 0),
                        'step': 'ì™„ë£Œ'
                    })
            else:
                logger.error(f"âŒ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: ì¢…ë£Œ ì½”ë“œ={return_code}")
                training_status['current_step'] = 'ì‹¤íŒ¨'
                training_status['is_running'] = False
                training_status['state'] = 'failed'
                training_status['is_complete'] = False
                training_status['log_entries'].append({
                    'message': f'âŒ ì‘ì—…ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤ (ì¢…ë£Œ ì½”ë“œ: {return_code})',
                    'level': 'error',
                    'timestamp': time.time(),
                    'epoch': training_status.get('current_epoch', 0),
                    'step': 'ì‹¤íŒ¨'
                })
    
    except Exception as e:
        logger.error(f"âŒ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì¼ë°˜ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        with training_lock:
            training_status['current_step'] = 'í•™ìŠµ ì˜¤ë¥˜'
            training_status['is_running'] = False
            training_status['state'] = 'failed'
            training_status['is_complete'] = False
            training_status['log_entries'].append({
                'message': f'âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
                'level': 'error',
                'timestamp': time.time()
            })
        print(f"âŒ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")
    
    finally:
        # ì›ë˜ ë””ë ‰í† ë¦¬ë¡œ ë³µê·€
        logger.info("ğŸ”„ ì›ë˜ ë””ë ‰í† ë¦¬ë¡œ ë³µê·€")
        os.chdir('..')
        logger.info(f"ğŸ“ í˜„ì¬ ë””ë ‰í† ë¦¬: {os.getcwd()}")


async def training_page_handler(request):
    """Training í˜ì´ì§€ í•¸ë“¤ëŸ¬"""
    return web.FileResponse('static/training.html')


async def dataset_info_handler(request):
    """ë°ì´í„°ì…‹ ì •ë³´ ì¡°íšŒ"""
    try:
        data_glob = request.query.get('data_glob', 'training/dataset/raw/*.jsonl')
        files = glob.glob(data_glob)
        
        total_size = 0
        file_info = []
        
        for file_path in files:
            if os.path.exists(file_path):
                size = os.path.getsize(file_path)
                total_size += size
                file_info.append({
                    'name': os.path.basename(file_path),
                    'size': size,
                    'path': file_path
                })
        
        return web.json_response({
            'status': 'ok',
            'total_files': len(files),
            'total_size': total_size,
            'files': file_info
        })
        
    except Exception as e:
        print(f"âŒ ë°ì´í„°ì…‹ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return web.json_response({"error": str(e)}, status=500)


async def training_start_handler(request):
    """í•™ìŠµ ì‹œì‘"""
    global training_process, training_status
    
    logger.info("ğŸ¯ í•™ìŠµ ì‹œì‘ ìš”ì²­ ìˆ˜ì‹ ")
    
    try:
        with training_lock:
            if training_status['is_running']:
                logger.warning("âš ï¸ í•™ìŠµì´ ì´ë¯¸ ì§„í–‰ ì¤‘")
                return web.json_response({"error": "í•™ìŠµì´ ì´ë¯¸ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤."}, status=400)
            
            data = await request.json()
            logger.info(f"ğŸ“‹ í•™ìŠµ ì„¤ì •: {data}")
            
            # í•™ìŠµ ì„¤ì • ê²€ì¦
            training_mode = data.get('training_mode', 'full')
            logger.info(f"ğŸ“‹ í•™ìŠµ ëª¨ë“œ: {training_mode}")
            
            if training_mode == 'full':
                # ì „ì²´ íŒŒì´í”„ë¼ì¸: í•™ìŠµ íŒŒë¼ë¯¸í„° í•„ìˆ˜
                required_fields = ['data_glob', 'window', 'stride', 'epochs', 'batch_size', 'lr']
                logger.info("ğŸ”§ ì „ì²´ íŒŒì´í”„ë¼ì¸ ëª¨ë“œ - í•™ìŠµ íŒŒë¼ë¯¸í„° ê²€ì¦")
            else:
                # í´ëŸ¬ìŠ¤í„°ë§ë§Œ: ê¸°ë³¸ íŒŒë¼ë¯¸í„°ì™€ ì„ë² ë”© íŒŒì¼ ê²½ë¡œ í•„ìˆ˜
                required_fields = ['data_glob', 'window', 'stride', 'embeddings_path']
                logger.info("ğŸ¯ í´ëŸ¬ìŠ¤í„°ë§ ì „ìš© ëª¨ë“œ - ì„ë² ë”© íŒŒì¼ ê²½ë¡œ ê²€ì¦")
            
            for field in required_fields:
                if field not in data:
                    logger.error(f"âŒ í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
                    return web.json_response({"error": f"í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {field}"}, status=400)
            
            # í´ëŸ¬ìŠ¤í„°ë§ë§Œ ëª¨ë“œì—ì„œ ì„ë² ë”© íŒŒì¼ ì¡´ì¬ í™•ì¸
            if training_mode == 'clustering':
                embeddings_path = data.get('embeddings_path', 'runs/embeddings.npy')
                logger.info(f"ğŸ“ ì„ë² ë”© íŒŒì¼ ê²½ë¡œ í™•ì¸: {embeddings_path}")
                
                # ì—¬ëŸ¬ ê°€ëŠ¥í•œ ê²½ë¡œì—ì„œ íŒŒì¼ ì°¾ê¸°
                possible_paths = [
                    embeddings_path,  # ì›ë³¸ ê²½ë¡œ
                    os.path.join(os.getcwd(), embeddings_path),  # í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€
                    os.path.join(os.getcwd(), 'training', embeddings_path),  # training í´ë” ê¸°ì¤€
                    os.path.join(os.getcwd(), '..', embeddings_path),  # ìƒìœ„ ë””ë ‰í† ë¦¬ ê¸°ì¤€
                ]
                
                found_path = None
                for path in possible_paths:
                    if os.path.exists(path):
                        found_path = path
                        break
                
                if not found_path:
                    # ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
                    current_dir = os.getcwd()
                    debug_info = f"""
í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {current_dir}
ì›ë³¸ ê²½ë¡œ: {embeddings_path}
í™•ì¸í•œ ê²½ë¡œë“¤:
{chr(10).join([f"  - {path} (ì¡´ì¬: {os.path.exists(path)})" for path in possible_paths])}
"""
                    return web.json_response({
                        "error": f"ì„ë² ë”© íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {embeddings_path}{debug_info}"
                    }, status=400)
                
                # ì°¾ì€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ì—…ë°ì´íŠ¸
                data['embeddings_path'] = os.path.abspath(found_path)
            
                # í•™ìŠµ ìƒíƒœ ì´ˆê¸°í™”
                training_status.update({
                'state': 'running',
                    'is_running': True,
                    'current_step': 'í•™ìŠµ ì¤€ë¹„ ì¤‘...',
                    'progress': 0,
                    'current_epoch': 0,
                    'total_epochs': data.get('epochs', 0) if training_mode == 'full' else 0,
                    'current_loss': 0,
                    'best_loss': None,
                    'start_time': time.time(),
                'log_entries': [],
                'is_complete': False
                })
            
            # í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
            training_process = threading.Thread(
                target=run_training_pipeline,
                args=(data,),
                daemon=True
            )
            training_process.start()
            
            print(f"ğŸš€ í•™ìŠµ ì‹œì‘: {data}")
            return web.json_response({
                'status': 'ok',
                'message': 'í•™ìŠµì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.'
            })
            
    except Exception as e:
        print(f"âŒ í•™ìŠµ ì‹œì‘ ì˜¤ë¥˜: {e}")
        return web.json_response({"error": str(e)}, status=500)


async def training_stop_handler(request):
    """í•™ìŠµ ì¤‘ì§€"""
    global training_process, training_status
    
    try:
        with training_lock:
            if not training_status['is_running']:
                return web.json_response({"error": "ì‹¤í–‰ ì¤‘ì¸ í•™ìŠµì´ ì—†ìŠµë‹ˆë‹¤."}, status=400)
            
            # í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì¤‘ì§€
            if training_process and training_process.is_alive():
                # í”„ë¡œì„¸ìŠ¤ ì¢…ë£ŒëŠ” run_training_pipelineì—ì„œ ì²˜ë¦¬
                pass
            
            training_status['is_running'] = False
            training_status['state'] = 'stopped'
            training_status['is_complete'] = False
            training_status['current_step'] = 'í•™ìŠµ ì¤‘ì§€ë¨'
            
            print("â¹ï¸ í•™ìŠµ ì¤‘ì§€ ìš”ì²­ë¨")
            return web.json_response({
                'status': 'ok',
                'message': 'í•™ìŠµ ì¤‘ì§€ ìš”ì²­ì´ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.'
            })
            
    except Exception as e:
        print(f"âŒ í•™ìŠµ ì¤‘ì§€ ì˜¤ë¥˜: {e}")
        return web.json_response({"error": str(e)}, status=500)


async def training_status_handler(request):
    """í•™ìŠµ ìƒíƒœ ì¡°íšŒ"""
    global training_status
    
    try:
        with training_lock:
            elapsed_time = 0
            if training_status['start_time']:
                elapsed_time = time.time() - training_status['start_time']
            
            status_data = training_status.copy()
            status_data['elapsed_time'] = elapsed_time
            # í˜¸í™˜ì„±: ì™„ë£Œ ì—¬ë¶€ê°€ ì—†ìœ¼ë©´ is_runningìœ¼ë¡œ ìœ ì¶”
            if 'is_complete' not in status_data:
                status_data['is_complete'] = (not status_data.get('is_running', False)) and status_data.get('progress', 0) >= 100
            # í˜¸í™˜ì„±: is_running/is_completeë¥¼ stateë¡œë¶€í„° ë³´ì •
            state = status_data.get('state')
            if state:
                status_data['is_running'] = (state == 'running')
                status_data['is_complete'] = (state == 'completed')
            
            # JSONì—ì„œ ìœ íš¨í•˜ì§€ ì•Šì€ ê°’ë“¤ì„ ì²˜ë¦¬
            if status_data['best_loss'] == float('inf'):
                status_data['best_loss'] = None
            
            return web.json_response({
                'status': 'ok',
                **status_data
            })
            
    except Exception as e:
        print(f"âŒ í•™ìŠµ ìƒíƒœ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return web.json_response({"error": str(e)}, status=500)


def setup_training_routes(app):
    """í•™ìŠµ ê´€ë ¨ ë¼ìš°íŠ¸ë“¤ì„ ì•±ì— ë“±ë¡"""
    # Training í˜ì´ì§€ ë¼ìš°íŠ¸
    app.router.add_get('/training', training_page_handler)
    
    # Training API ë¼ìš°íŠ¸
    app.router.add_get("/training/dataset-info", dataset_info_handler)
    app.router.add_post("/training/start", training_start_handler)
    app.router.add_post("/training/stop", training_stop_handler)
    app.router.add_get("/training/status", training_status_handler)
    
    print("âœ… Training routes registered successfully")


def get_training_status():
    """í•™ìŠµ ìƒíƒœ ì¡°íšŒ (ì™¸ë¶€ì—ì„œ ì‚¬ìš©)"""
    global training_status
    with training_lock:
        return training_status.copy()


def is_training_running():
    """í•™ìŠµ ì‹¤í–‰ ì—¬ë¶€ í™•ì¸ (ì™¸ë¶€ì—ì„œ ì‚¬ìš©)"""
    global training_status
    with training_lock:
        return training_status['is_running']
